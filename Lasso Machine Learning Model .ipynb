{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ad Targeting LASSO Regression Model \n",
    "## By Colin Bayer\n",
    "### Created for APRD6342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Import Packgeges ##\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "## Import Data ##\n",
    "## finalmaster-ratios.csv ##\n",
    "\n",
    "filename = 'finalmaster-ratios.csv'\n",
    "fmData = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "\n",
    "## Create a List of all Predictors ##\n",
    "allvariablenames = list(fmData.columns.values)\n",
    "\n",
    "## Remove the first 8 values in the list ##\n",
    "del allvariablenames[0:7]\n",
    "\n",
    "\n",
    "## Get Coloumns ready ##\n",
    "## Load Predictors into data frame ##\n",
    "predictors = fmData[allvariablenames]\n",
    "\n",
    "## Load Target into Data frame ##\n",
    "target = fmData['# Purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.040e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.464e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.318e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.233e-01, previous alpha=3.226e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=9.605e-02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=5.356e-02, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.802e-02, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.799e-02, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.799e-02, with an active set of 84 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.757e-02, with an active set of 84 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 113 iterations, alpha=4.799e-02, previous alpha=4.540e-02, with an active set of 84 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.232e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.616e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.507e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=1.220e-01, previous alpha=1.220e-01, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.960e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.991e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.991e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=5.901e-01, previous alpha=5.579e-01, with an active set of 14 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.443e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.364e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.752e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.752e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.189e-01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.166e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=1.030e-01, previous alpha=1.004e-01, with an active set of 63 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=9.772e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.659e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=7.158e-01, previous alpha=6.983e-01, with an active set of 12 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.033e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.189e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.471e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.066e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.033e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.217e-01, previous alpha=5.033e-01, with an active set of 15 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.095e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.017e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=8.104e-02, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=8.104e-02, with an active set of 52 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=8.026e-02, previous alpha=7.912e-02, with an active set of 55 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.442e+00, with an active set of 3 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.209e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.699e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.106e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=2.993e-01, previous alpha=2.901e-01, with an active set of 23 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.554e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.613e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01001014' 0.7975260265569238]\n",
      "['B01001036' 2.4975987120275827]\n",
      "['B01001037' 1.5798278110427166]\n",
      "['B01001038' 1.6358596519844413]\n",
      "['B02001005' 0.49093615792653633]\n",
      "['B13014016' 0.009433958279257113]\n",
      "['B13014026' 0.4955798244683253]\n",
      "['B13014027' 0.33105609299067307]\n",
      "['B15002015' 0.04187704921035053]\n",
      "['B15002027' 0.9363990047138775]\n",
      "['B19001017' 1.4673678524497002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.229e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=2.269e-01, previous alpha=2.177e-01, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.539e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.788e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.957e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.420e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.247e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/colin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=4.564e-01, previous alpha=4.247e-01, with an active set of 17 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## Split Data into Train and test sets, with 30% retaied for tests ##\n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)\n",
    "\n",
    "\n",
    "## Build Lasso Model ##\n",
    "model = LassoLarsCV( cv = 10 ,precompute = False)\n",
    "\n",
    "model.fit(pred_train, tar_train)\n",
    "\n",
    "## Build Coefficent Chart ##\n",
    "predictors_model=pd.DataFrame(allvariablenames)\n",
    "predictors_model.columns = ['label']\n",
    "predictors_model['coeff'] = model.coef_\n",
    "\n",
    "\n",
    "for index, row in predictors_model.iterrows():\n",
    "    if row['coeff'] > 0:\n",
    "        print(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q #1: Coefficent Chart\n",
      "==========================\n",
      " What this is realy doing is finding the Variables or predictors that have a postitve impact on the target Varibale\n",
      " If you increase these variables, Purchases should increase as well\n"
     ]
    }
   ],
   "source": [
    "print('\\nQ #1: Coefficent Chart')        \n",
    "print('==========================')\n",
    "print(' What this is realy doing is finding the Variables or predictors that have a postitve impact on the target Varibale')\n",
    "print(' If you increase these variables, Purchases should increase as well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q # 2: What Census Variable most predicts sales\n",
      "====================================================\n",
      " Find the variables that predict the most sales \n",
      "B01001036 2.4975987120275827, In areas where there are more females aged 30-34, we sell more Bobo Bars\n",
      "B01001038 1.6358596519844413,  In areas where there are more females aged 40-44, we sell more Bobo Bars \n",
      "B01001037 1.5798278110427166, In areas where there are more females aged 35-39, we sell more Bobo Bars \n",
      "B19001017 1.4673678524497002, In areas where house Hold income is more than $200,000 the past 12 months, will sell more Bobo Bars\n",
      "B15002027 0.9363990047138775, In areas where there have people are more educated we sell more Bobo Bars\n",
      "B01001014 0.7975260265569238,in areas where there are more males aged 40 to 44 we sell more Bobo Bars \n",
      "B13014026 0.4955798244683253, in areas where there are more women who have gave birht in the past 12 moths, we sell more Bobo Bars\n",
      "B02001005 0.49093615792653633, in areas where there are moe Asian people, we sell more Bobo bars\n",
      "B13014027 0.33105609299067307,in areas where women have givern birth in the past 12 months, are married, and educated, we sell more bob bars\n",
      "B15002015 0.04187704921035053, in areas where people are over the age of 25 and have their bachelors degree, we sell more Bobo bars\n",
      "B13014016 0.009433958279257113, in areas where more women aged 15-50 who gave birth in the past 12 months, are married, and educated, will sell more Bobo Bars\n",
      " Summary of Findings:  Overall the data seems to hint that in areas where there are more middle aged and high middle class families, we would expect to seel the most Bobo Bars\n"
     ]
    }
   ],
   "source": [
    "print ('\\nQ # 2: What Census Variable most predicts sales')\n",
    "print('====================================================')\n",
    "print(' Find the variables that predict the most sales ')\n",
    "print( 'B01001036 2.4975987120275827, In areas where there are more females aged 30-34, we sell more Bobo Bars')\n",
    "print('B01001038 1.6358596519844413,  In areas where there are more females aged 40-44, we sell more Bobo Bars ')\n",
    "print( 'B01001037 1.5798278110427166, In areas where there are more females aged 35-39, we sell more Bobo Bars ')\n",
    "print( 'B19001017 1.4673678524497002, In areas where house Hold income is more than $200,000 the past 12 months, will sell more Bobo Bars')\n",
    "print('B15002027 0.9363990047138775, In areas where there have people are more educated we sell more Bobo Bars')\n",
    "print('B01001014 0.7975260265569238,in areas where there are more males aged 40 to 44 we sell more Bobo Bars ')\n",
    "print('B13014026 0.4955798244683253, in areas where there are more women who have gave birht in the past 12 moths, we sell more Bobo Bars')\n",
    "print('B02001005 0.49093615792653633, in areas where there are moe Asian people, we sell more Bobo bars')\n",
    "print('B13014027 0.33105609299067307,in areas where women have givern birth in the past 12 months, are married, and educated, we sell more bob bars')\n",
    "print('B15002015 0.04187704921035053, in areas where people are over the age of 25 and have their bachelors degree, we sell more Bobo bars')\n",
    "print('B13014016 0.009433958279257113, in areas where more women aged 15-50 who gave birth in the past 12 months, are married, and educated, will sell more Bobo Bars')\n",
    "print(' Summary of Findings:  Overall the data seems to hint that in areas where there are more middle aged and high middle class families, we would expect to seel the most Bobo Bars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q # 3: Top two census Variables\n",
      "=======================================\n",
      " Two Variables that most steeply predict sales \n",
      "B01001036 2.4975987120275827, In areas where there are more females aged 30-34, we sell more Bobo Bars \n",
      "B01001038 1.6358596519844413,  In areas where there are more females aged 40-44, we sell more Bobo Bars \n"
     ]
    }
   ],
   "source": [
    "print('\\nQ # 3: Top two census Variables')\n",
    "print('=======================================')\n",
    "print(' Two Variables that most steeply predict sales ')\n",
    "print( 'B01001036 2.4975987120275827, In areas where there are more females aged 30-34, we sell more Bobo Bars ')\n",
    "print( 'B01001038 1.6358596519844413,  In areas where there are more females aged 40-44, we sell more Bobo Bars ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q # 4  \n",
      "================================================================\n",
      " Compare Mean Squared Error of the training data and the testing data\n",
      "training data MSE\n",
      "21778.404136729267\n",
      "Testing data MSE\n",
      "40253.19121251069\n",
      " Mean Squared Error describes possible error in the model \n",
      " The Smaller the MSE the better the model perfroms\n",
      " This indicates that the training data is a better fit than the testing data \n",
      " That being said though both the train and test data sets in the lasso model have a high Mean Square Error, meaning that the variance and Volitility in the data sets is very high\n",
      " This may be an indication that this model is not good or intuitive\n"
     ]
    }
   ],
   "source": [
    "print('\\nQ # 4  ')\n",
    "print('================================================================')\n",
    "print(' Compare Mean Squared Error of the training data and the testing data')\n",
    "\n",
    "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "print ('training data MSE')\n",
    "print(train_error)\n",
    "\n",
    "\n",
    "\n",
    "test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
    "print ('Testing data MSE')\n",
    "print(test_error)\n",
    "\n",
    "print(' Mean Squared Error describes possible error in the model ')\n",
    "print(' The Smaller the MSE the better the model perfroms')\n",
    "print(' This indicates that the training data is a better fit than the testing data ')\n",
    "print(' That being said though both the train and test data sets in the lasso model have a high Mean Square Error, meaning that the variance and Volitility in the data sets is very high')\n",
    "print(' This may be an indication that this model is not good or intuitive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q # 5: R Squared\n",
      "==========================================\n",
      " Training Data R-Squared\n",
      "training data R-square\n",
      "0.24854772534412184\n",
      " Testing Data R-Squared \n",
      "testing data R-square\n",
      "0.2015761469701496\n",
      "R-Squared is a statistical Measure that determines that Used to determine a goodness of fit of a regressiona model \n",
      " Between 0-1 \n",
      " Closer to 1 the better \n",
      " since the training data has a higher R-squared, it means that it has a better fit to its model than the Testing Data\n",
      " That being said it is very low, so neither the train nor test model has a good fit to the model \n",
      " The census data does not do a great job of predicting sales \n"
     ]
    }
   ],
   "source": [
    "print('\\nQ # 5: R Squared') \n",
    "print('==========================================')\n",
    "print(' Training Data R-Squared')\n",
    "rsquared_train=model.score(pred_train,tar_train)\n",
    "print ('training data R-square')\n",
    "print(rsquared_train)\n",
    "\n",
    "print(' Testing Data R-Squared ')\n",
    "rsquared_test=model.score(pred_test,tar_test)\n",
    "print ('testing data R-square')\n",
    "print(rsquared_test)\n",
    "print('R-Squared is a statistical Measure that determines that Used to determine a goodness of fit of a regressiona model ')\n",
    "print(' Between 0-1 ')\n",
    "print(' Closer to 1 the better ')\n",
    "print(' since the training data has a higher R-squared, it means that it has a better fit to its model than the Testing Data')\n",
    "print(' That being said it is very low, so neither the train nor test model has a good fit to the model ')\n",
    "\n",
    "print(' The census data does not do a great job of predicting sales ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q # 6: Y intercept\n",
      "======================================================\n",
      " Y-intercept \n",
      "y interecept:\n",
      "1.7055050823839224\n",
      " This number represents sales if all other variables are equal to 0\n",
      " Conceptually this indicates the sales if no other factors are considered\n"
     ]
    }
   ],
   "source": [
    "print('\\nQ # 6: Y intercept')\n",
    "print('======================================================')\n",
    "print(' Y-intercept ')\n",
    "print(\"y interecept:\")\n",
    "print(model.intercept_)\n",
    "\n",
    "print(' This number represents sales if all other variables are equal to 0') \n",
    "print(' Conceptually this indicates the sales if no other factors are considered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
